import Head from "next/head";
import { Inter } from "next/font/google";
import { useSpeechRecognition } from "@/hooks/speech/useSpeechRecognition";
import { AnimatedTranscript } from "@/AnimatedTranscript";
import { useState } from "react";

const inter = Inter({ subsets: ["latin"] });

export default function Home() {
  const speechRecognition = useSpeechRecognition({ language: "en-US" });
  const [showAnimatedTranscript, setShowAnimatedTranscript] = useState(false);

  return (
    <>
      <Head>
        <title>Ngomong</title>
        <meta name="description" content="Generated by create next app" />
        <meta name="viewport" content="width=device-width, initial-scale=1" />
        <link rel="icon" href="/favicon.ico" />
      </Head>
      <main>
        <button onClick={speechRecognition.toggleListeningState}>
          {speechRecognition.isListening ? "Stop" : "Start"}
        </button>
        <p>{speechRecognition.isListening && "Listening..."}</p>

        <div>
          <span
            dangerouslySetInnerHTML={{ __html: speechRecognition.output }}
          />{" "}
          <br />
          <span className="opacity-50">{speechRecognition.interimOutput}</span>
        </div>

        <div>
          {speechRecognition.detailedTranscripts.map((transcript, index) => (
            <div key={index}>
              {transcript.transcript} start: {transcript.startTimestamp}{" "}
              duration: {transcript.duration}
            </div>
          ))}
        </div>

        {!speechRecognition.isListening &&
          speechRecognition.detailedTranscripts.length > 0 && (
            <button onClick={() => setShowAnimatedTranscript((prev) => !prev)}>
              Show animated transcript
            </button>
          )}

        {showAnimatedTranscript && (
          <AnimatedTranscript
            detailedTranscripts={speechRecognition.detailedTranscripts}
          />
        )}
      </main>
    </>
  );
}
